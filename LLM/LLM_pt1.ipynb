{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "902d8260b4c044a9a34e57fa3bd5e811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee35e3d11c6f4dec8072129a50282c15",
              "IPY_MODEL_c581d7dd03f64eb0b7b110024974d36b",
              "IPY_MODEL_1afb8730ecc44194bb2771963beaf54e"
            ],
            "layout": "IPY_MODEL_2e1e8655350f499eb755879dc0d8b7b9"
          }
        },
        "ee35e3d11c6f4dec8072129a50282c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb1c57e540e4b4da079a29b4b1bd891",
            "placeholder": "​",
            "style": "IPY_MODEL_7e8d450b484448478ab443436cf67150",
            "value": "  0%"
          }
        },
        "c581d7dd03f64eb0b7b110024974d36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f71f76990ae435da06209093ef2f94a",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7da829f1036a4ad786494388de2cfd06",
            "value": 0
          }
        },
        "1afb8730ecc44194bb2771963beaf54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef0516c1766d48eb87c603d483b4299c",
            "placeholder": "​",
            "style": "IPY_MODEL_2b6f608d3fee40f096a253fa6f676632",
            "value": " 0/6 [00:00&lt;?, ?it/s]"
          }
        },
        "2e1e8655350f499eb755879dc0d8b7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb1c57e540e4b4da079a29b4b1bd891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8d450b484448478ab443436cf67150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f71f76990ae435da06209093ef2f94a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da829f1036a4ad786494388de2cfd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef0516c1766d48eb87c603d483b4299c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b6f608d3fee40f096a253fa6f676632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Email Spam Classification with a Large Language Model (LLM)**\n",
        "In this notebook, we will:\n",
        "\n",
        "Load a pre-trained instruction-following model from Hugging Face\n",
        "\n",
        "Import the spam.csv dataset\n",
        "\n",
        "Apply prompt engineering to classify each email as either spam or ham (not spam)\n",
        "\n",
        "Configure the model to output only the class label for each email\n",
        "\n"
      ],
      "metadata": {
        "id": "KmxiqjpZYxNx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4uw7chCYs_H",
        "outputId": "8aff58c1-f3f6-425f-e0d6-934472a9bb78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers pandas tqdm\n",
        "\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Load the LLM and Set Up a Text-to-Text Generation Pipeline**\n",
        "We’ll utilize the google/flan-t5-base model, a flexible Seq2Seq instruction-following model. The pipeline will be configured to produce a single-token output, either \"spam\" or \"ham.\""
      ],
      "metadata": {
        "id": "-UcMBvCNZDQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('/content/spam.csv', encoding='latin1')\n",
        "    print(\"Dataset loaded successfully. Here's a preview:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nDataset info:\")\n",
        "    print(df.info())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: spam.csv not found. Make sure the file is in the same directory as your script.\")\n",
        "    # Exit or handle the error appropriately if the file isn't found\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfgJwJoXZHVn",
        "outputId": "29e0b98c-7d08-4f44-eb4d-88368a5d44c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully. Here's a preview:\n",
            "                                                text target\n",
            "0  Go until jurong point, crazy.. Available only ...    ham\n",
            "1                      Ok lar... Joking wif u oni...    ham\n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   spam\n",
            "3  U dun say so early hor... U c already then say...    ham\n",
            "4  Nah I don't think he goes to usf, he lives aro...    ham\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5572 non-null   object\n",
            " 1   target  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Define the Prompt Template and Classification Function**\n",
        "We design a prompt that explicitly directs the model to return only the class label, and limit the generation to a brief maximum length to ensure concise outputs."
      ],
      "metadata": {
        "id": "dPPAp5SFZJ6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify a batch of emails using the loaded LLM\n",
        "def classify_email_batch(texts):\n",
        "    predicted_labels = []\n",
        "    # Loop through each text in the batch\n",
        "    for text in texts:\n",
        "        # Prompt Engineering\n",
        "        prompt = f\"Classify the following email as 'ham' or 'spam'. Respond with only 'ham' or 'spam'.\\n\\nEmail: \\\"{text}\\\"\\nClassification:\"\n",
        "\n",
        "        try:\n",
        "            # Step 3b: Perform LLM inference\n",
        "            llm_output = classifier(prompt)[0]['label']\n",
        "\n",
        "            # Step 3c: Map LLM output to 'ham' or 'spam' (if necessary)\n",
        "\n",
        "            if llm_output == 'POSITIVE': # Assuming 'POSITIVE' might relate to ham (or spam depending on context)\n",
        "                final_label = 'ham'\n",
        "            elif llm_output == 'NEGATIVE': # Assuming 'NEGATIVE' might relate to spam (or ham)\n",
        "                final_label = 'spam'\n",
        "            else:\n",
        "\n",
        "                final_label = llm_output.lower()\n",
        "\n",
        "            predicted_labels.append(final_label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error classifying email: '{text[:50]}...' - {e}\")\n",
        "            predicted_labels.append(\"error_in_classification\")\n",
        "    return predicted_labels\n",
        "\n",
        "print(\"\\nBatch classification function defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilvdrDZPZNbB",
        "outputId": "dc1c84d6-14a8-4993-ac40-8f03632d3c71"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch classification function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Load the Dataset and Perform Classification**\n",
        "We’ll load the spam.csv file, classify each email using the model, and append a new column containing the predicted spam or ham label."
      ],
      "metadata": {
        "id": "LYz9R7WvZPZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store all predicted targets\n",
        "all_predicted_targets = []\n",
        "\n",
        "# Define batch size (adjust based on your system's memory and LLM's capacity)\n",
        "batch_size = 1000 # Start with a small batch size, e.g., 1000 or 20000, then increase if stable.\n",
        "\n",
        "print(f\"\\nStarting batch processing with batch size: {batch_size}\")\n",
        "print(f\"Total emails to process: {len(df)}\")\n",
        "\n",
        "# Define the batch classification function\n",
        "def classify_email_batch(texts: list[str]) -> list[str]:\n",
        "    \"\"\"Classifies a batch of emails using the pre-defined classifier.\"\"\"\n",
        "    return [classify_email(text) for text in texts]\n",
        "\n",
        "# Process the DataFrame in batches\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    # Get the current batch of texts\n",
        "    batch_df = df.iloc[i:i + batch_size]\n",
        "    batch_texts = batch_df['text'].tolist()\n",
        "\n",
        "    if not batch_texts: # Skip if batch is empty (can happen at the very end)\n",
        "        continue\n",
        "\n",
        "    # print(f\"Processing emails {i} to {min(i + batch_size, len(df))}...\")\n",
        "\n",
        "    # Get predictions for the current batch using your LLM\n",
        "    predicted_labels = classify_email_batch(batch_texts)\n",
        "\n",
        "    # Extend the main list of predictions\n",
        "    all_predicted_targets.extend(predicted_labels)\n",
        "\n",
        "print(\"\\nBatch processing complete.\")\n",
        "\n",
        "# Add the predicted labels to the DataFrame\n",
        "df['predicted'] = all_predicted_targets\n",
        "\n",
        "display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "902d8260b4c044a9a34e57fa3bd5e811",
            "ee35e3d11c6f4dec8072129a50282c15",
            "c581d7dd03f64eb0b7b110024974d36b",
            "1afb8730ecc44194bb2771963beaf54e",
            "2e1e8655350f499eb755879dc0d8b7b9",
            "bfb1c57e540e4b4da079a29b4b1bd891",
            "7e8d450b484448478ab443436cf67150",
            "4f71f76990ae435da06209093ef2f94a",
            "7da829f1036a4ad786494388de2cfd06",
            "ef0516c1766d48eb87c603d483b4299c",
            "2b6f608d3fee40f096a253fa6f676632"
          ]
        },
        "id": "DAwB4KuIZTTX",
        "outputId": "2c62e1fc-c71b-494f-9a60-0ae318d492ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting batch processing with batch size: 1000\n",
            "Total emails to process: 5572\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "902d8260b4c044a9a34e57fa3bd5e811"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Evaluate and Display Sample Results**\n",
        "We’ll calculate key metrics including accuracy, F1-score, recall, and generate a confusion matrix to assess the classification performance."
      ],
      "metadata": {
        "id": "Pz5OxLsgZaH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the predicted targets back to the original DataFrame\n",
        "if len(all_predicted_targets) == len(df):\n",
        "    df['predicted_target'] = all_predicted_targets\n",
        "    print(\"\\nPredicted targets added to DataFrame. Here's a sample:\")\n",
        "    print(df[['text', 'target', 'predicted_target']].head(10))\n",
        "\n",
        "    # Basic Evaluation (Optional, but recommended)\n",
        "    from sklearn.metrics import accuracy_score, classification_report\n",
        "    df['target_normalized'] = df['target'].apply(lambda x: x.strip().lower())\n",
        "    df['predicted_target_normalized'] = df['predicted_target'].apply(lambda x: x.strip().lower())\n",
        "\n",
        "    # Filter out any 'error_in_classification'\n",
        "    valid_predictions_df = df[df['predicted_target_normalized'] != 'error_in_classification']\n",
        "\n",
        "    if not valid_predictions_df.empty:\n",
        "        true_labels = valid_predictions_df['target_normalized']\n",
        "        pred_labels = valid_predictions_df['predicted_target_normalized']\n",
        "\n",
        "        # Get unique labels from both true and predicted sets for consistent reporting\n",
        "        all_labels = sorted(list(set(true_labels.tolist() + pred_labels.tolist())))\n",
        "\n",
        "        print(f\"\\nAccuracy: {accuracy_score(true_labels, pred_labels):.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(true_labels, pred_labels, labels=all_labels, zero_division=0))\n",
        "    else:\n",
        "        print(\"\\nNo valid predictions to evaluate.\")\n",
        "\n",
        "else:\n",
        "    print(f\"Mismatch in number of predictions ({len(all_predicted_targets)}) and emails ({len(df)}).\")\n",
        "    print(\"Something went wrong during batch processing.\")\n",
        "\n",
        "print(\"\\nPractical Exercise 1: Email classification setup complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "KnMVKZt7ZbXl",
        "outputId": "78adaf7b-8080-4e73-d36c-0ea4fd562efe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'predicted'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'predicted'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-571849027.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy:.2%}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'predicted'"
          ]
        }
      ]
    }
  ]
}